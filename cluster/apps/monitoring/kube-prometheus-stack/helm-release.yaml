---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 18.0.0
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  interval: 5m
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    alertmanager:
      enabled: true
      config:
        global:
          smtp_to: ${SECRET_EMAIL}
          smtp_from: prometheus@tuxpeople.org
          smtp_smarthost: smtp.utils.svc.cluster.local:25
          smtp_require_tls: false
        #  smtp_smarthost: smtp.gmail.com:587
        #  smtp_auth_username: you@gmail.com
        #  smtp_auth_password: yourapppassword # https://support.google.com/mail/answer/185833?hl=en-GB
        #  smtp_auth_identity: you@gmail.com
        route:
          group_by: ['job']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 1h
          receiver: email
          routes:
          - match:
              alertname: Watchdog
            receiver: 'DeadMansSnitch'
          - match:
              alertname: CPUThrottlingHigh
            receiver: 'email'
          - match:
              alertname: KubeMemoryOvercommit
            receiver: 'email'
          - match:
              alertname: KubeCPUOvercommit
            receiver: 'email'
          - match:
              alertname: KubeletTooManyPods
            receiver: 'email'

        receivers:
        - name: 'null'
        - name: email
          email_configs:
          - send_resolved: true
            to: youremail@gmail.com
        - name: DeadMansSnitch
          webhook_config:
          - url: https://nosnch.in/c15491ac44

        # Inhibition rules allow to mute a set of alerts given that another alert is firing.
        # We use this to mute any warning-level notifications if the same alert is already critical.
        inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          # Apply inhibition if the alertname is the same.
          equal: ['alertname', 'namespace']

      alertmanagerSpec:
    #    replicas: 3
    #    podAntiAffinity: "soft"
        storage:
          volumeClaimTemplate:
            spec:
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 1Gi
    #    resources:
    #      limits:
    #        cpu: 500m
    #        memory: 64Mi
    #      requests:
    #        cpu: 25m
    #        memory: 32Mi
    #    priorityClassName: high-priority
    nodeExporter:
      serviceMonitor:
        relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
          - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
    grafana:
      enabled: false
    # Disable etcd monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/4
    kubeEtcd:
      enabled: false
    # Disable kube-controller-manager and kube-scheduler monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/2
    kubeControllerManager:
      enabled: false
    kubeScheduler:
      enabled: false
    kubeProxy:
      enabled: false
    kubelet:
      serviceMonitor:
        metricRelabelings:
        - action: replace
          sourceLabels:
          - node
          targetLabel: instance
    prometheus:
      enabled: true
      persistentVolume:
        enabled: true
        size: 10Gi
      ingress:
        enabled: true
        pathType: Prefix
        hosts:
        - prometheus.${SECRET_DOMAIN_INTERNAL}
        annotations:
          kubernetes.io/ingress.class: traefik
      prometheusSpec:
        podAntiAffinity: "hard"
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 14d
        enableAdminAPI: true
        walCompression: true
        additionalScrapeConfigs:
        - job_name: 'speedtest-exporter'
          scrape_interval: 1h
          scrape_timeout: 1m
          static_configs:
          - targets: ['speedtest-exporter:9798']
        - job_name: 'haproxy'
          static_configs:
          - targets:
            - k3s-lb1:1936
            - k3s-lb2:1936
        - job_name: 'node-exporter'
          honor_timestamps: true
          basic_auth:
            username: randomuser
            password: examplepassword
          static_configs:
          - targets:
            # nas
            - 10.20.30.40:9100
            # lab1
            - 192.168.8.11:9100
            # lab2
            - 192.168.8.12:9100
        # - job_name: 'unifipoller'
        #   scrape_interval: 30s
        #   static_configs:
        #   - targets: ['unifi-poller:9130']
        # - job_name: 'uptimerobot-prometheus'
        #   scrape_interval: 30s
        #   static_configs:
        #   - targets: ['uptimerobot-prometheus:9705']
        - job_name: 'kubernetes-service-endpoints'
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: kubernetes_node
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            regex: (https?)
            target_label: __scheme__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
          - source_labels: [__meta_kubernetes_pod_phase]
            regex: Pending|Succeeded|Failed
            action: drop
