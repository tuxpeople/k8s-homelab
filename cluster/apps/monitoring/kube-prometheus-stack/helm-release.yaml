---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 18.0.0
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  interval: 5m
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    alertmanager:
      enabled: true
      config:
        global:
          smtp_to: ${SECRET_EMAIL}
          smtp_from: prometheus@tuxpeople.org
          smtp_smarthost: smtp.utils.svc.cluster.local:25
          smtp_require_tls: false
        #  smtp_smarthost: smtp.gmail.com:587
        #  smtp_auth_username: you@gmail.com
        #  smtp_auth_password: yourapppassword # https://support.google.com/mail/answer/185833?hl=en-GB
        #  smtp_auth_identity: you@gmail.com
        route:
          group_by: ['job']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 1h
          receiver: email
          routes:
          - match:
              alertname: Watchdog
            receiver: 'DeadMansSnitch'
          - match:
              alertname: CPUThrottlingHigh
            receiver: 'email'
          - match:
              alertname: KubeMemoryOvercommit
            receiver: 'email'
          - match:
              alertname: KubeCPUOvercommit
            receiver: 'email'
          - match:
              alertname: KubeletTooManyPods
            receiver: 'email'

        receivers:
        - name: 'null'
        - name: email
          email_configs:
          - send_resolved: true
            to: youremail@gmail.com
        - name: DeadMansSnitch
          webhook_config:
          - url: https://nosnch.in/c15491ac44

        # Inhibition rules allow to mute a set of alerts given that another alert is firing.
        # We use this to mute any warning-level notifications if the same alert is already critical.
        inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          # Apply inhibition if the alertname is the same.
          equal: ['alertname', 'namespace']

      alertmanagerSpec:
    #    replicas: 3
    #    podAntiAffinity: "soft"
        storage:
          volumeClaimTemplate:
            spec:
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 1Gi
    #    resources:
    #      limits:
    #        cpu: 500m
    #        memory: 64Mi
    #      requests:
    #        cpu: 25m
    #        memory: 32Mi
    #    priorityClassName: high-priority
    nodeExporter:
      serviceMonitor:
        relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
          - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
    grafana:
      enabled: true
      deploymentStrategy:
        type: Recreate
      grafana.ini:
        server:
          root_url: https://grafana.${SECRET_DOMAIN_ME}
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
          - name: 'default'
            orgId: 1
            folder: ''
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/default
          - name: unifi
            orgId: 1
            folder: 'Unifi'
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/unifi
          - name: gitops
            orgId: 1
            folder: 'GitOps'
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/gitops
          - name: systems
            orgId: 1
            folder: 'Systems'
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/systems
          - name: networking
            orgId: 1
            folder: 'Networking'
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/networking
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
          - name: Prometheus
            type: prometheus
            url: http://prometheus-operated:9090
            access: proxy
            isDefault: true
          - name: Loki
            type: loki
            access: proxy
            url: http://loki:3100
      dashboards:
        unifi:
          # Ref: https://grafana.com/grafana/dashboards/11315/revisions
          unifi-client-insights:
            gnetId: 11315
            revision: 8
            datasource: Prometheus
          # Ref: https://grafana.com/grafana/dashboards/11311/revisions
          unifi-network-sites:
            gnetId: 11311
            revision: 4
            datasource: Prometheus
          # Ref: https://grafana.com/grafana/dashboards/11314/revisions
          unifi-uap-insights:
            gnetId: 11314
            revision: 9
            datasource: Prometheus
          # Ref: https://grafana.com/grafana/dashboards/11312/revisions
          unifi-usw-insights:
            gnetId: 11312
            revision: 8
            datasource: Prometheus
          # ?? Ref: https://grafana.com/grafana/dashboards/11313/revisions
          up_usg_insights:
            gnetId: 11313
            datasource: Prometheus
            revision: 8
          # ?? Ref: https://grafana.com/grafana/dashboards/11310/revisions
          #up_client-dpi:
          #  gnetId: 11310
          #  datasource: Prometheus
          #  revision: 4
        gitops:
          flux-cluster:
            url: https://raw.githubusercontent.com/fluxcd/flux2/main/manifests/monitoring/grafana/dashboards/cluster.json
            datasource: Prometheus
          flux-control-plane:
            url: https://raw.githubusercontent.com/fluxcd/flux2/main/manifests/monitoring/grafana/dashboards/control-plane.json
            datasource: Prometheus
        systems:
          # Ref: https://grafana.com/grafana/dashboards/1860/revisions
          node-exporter-full:
            gnetId: 1860
            datasource: Prometheus
            revision: 23
        networking:
          # Ref: https://grafana.com/grafana/dashboards/4475/revisions
          traefik:
            gnetId: 4475
            datasource: Prometheus
            revision: 5
          # Ref: https://grafana.com/grafana/dashboards/12693/revisions
          haproxy:
            gnetId: 12693
            datasource: Prometheus
            revision: 3
          # Ref: https://grafana.com/grafana/dashboards/13665/revisions
          speedtest:
            gnetId: 13665
            revision: 1
            datasource: Prometheus
          # Ref: https://grafana.com/grafana/dashboards/9955/revisions
          uptimerobot:
            gnetId: 9955
            datasource: Prometheus
            revision: 1
      sidecar:
        dashboards:
          enabled: true
          searchNamespace: ALL
        datasources:
          enabled: true
          searchNamespace: ALL
      plugins:
      - natel-discrete-panel
      - pr0ps-trackmap-panel
      - grafana-piechart-panel
      - vonage-status-panel
      - grafana-worldmap-panel
      - grafana-clock-panel
      serviceMonitor:
        enabled: true
      ingress:
        enabled: true
        hosts:
        - grafana.${SECRET_DOMAIN_ME}
        annotations:
          kubernetes.io/ingress.class: traefik
          cert-manager.io/cluster-issuer: letsencrypt-production
          traefik.ingress.kubernetes.io/redirect-entry-point: https
        tls:
        - secretName: grafana-tls
          hosts:
          - grafana.${SECRET_DOMAIN_ME}
      persistence:
        type: pvc
        enabled: true
        accessModes:
        - ReadWriteOnce
        size: 10Gi
    valuesFrom:
    - secretKeyRef:
      kind: Secret
      name: grafanavalues
    # Disable etcd monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/4
    kubeEtcd:
      enabled: false
    # Disable kube-controller-manager and kube-scheduler monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/2
    kubeControllerManager:
      enabled: false
    kubeScheduler:
      enabled: false
    kubeProxy:
      enabled: false
    kubelet:
      serviceMonitor:
        metricRelabelings:
        - action: replace
          sourceLabels:
          - node
          targetLabel: instance
    prometheus:
      enabled: true
      persistentVolume:
        enabled: true
        size: 10Gi
      ingress:
        enabled: true
        pathType: Prefix
        hosts:
        - prometheus.${SECRET_DOMAIN_INTERNAL}
        annotations:
          kubernetes.io/ingress.class: traefik
      prometheusSpec:
        podAntiAffinity: "hard"
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        scrape_interval: 10s
        podMonitorSelectorNilUsesHelmValues: false
        retention: 14d
        enableAdminAPI: true
        walCompression: true
        additionalScrapeConfigs:
        - job_name: 'speedtest-exporter'
          scrape_interval: 1h
          scrape_timeout: 1m
          static_configs:
          - targets: ['speedtest-exporter:9798']
        - job_name: 'haproxy'
          static_configs:
          - targets: ['k3s-lb1:1936'] # nas
            labels:
              alias: LB1
          - targets: ['k3s-lb2:1936'] # nas
            labels:
              alias: LB2
        - job_name: 'node-exporter'
          honor_timestamps: true
          basic_auth:
            username: randomuser
            password: examplepassword
          static_configs:
          - targets: ['10.20.30.40:9100'] # nas
            labels:
              alias: NAS
          - targets: ['192.168.8.11:9100'] # lab1
            labels:
              alias: lab1
          - targets: ['192.168.8.12:9100'] # lab2
            labels:
              alias: lab2
        # - job_name: 'unifipoller'
        #   scrape_interval: 30s
        #   static_configs:
        #   - targets: ['unifi-poller:9130']
        # - job_name: 'uptimerobot-prometheus'
        #   scrape_interval: 30s
        #   static_configs:
        #   - targets: ['uptimerobot-prometheus:9705']
        - job_name: 'kubernetes-service-endpoints'
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: kubernetes_node
        # Kubernetes API
        - job_name: kubernetes-apiserver
          kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
              - default
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
          - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: kubernetes;https
        # Kubernetes pods
        - job_name: kubernetes-pods
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: pod
